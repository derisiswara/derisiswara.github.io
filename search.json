[
  {
    "objectID": "projects/2025_05_03_dashboard_omnitest.html",
    "href": "projects/2025_05_03_dashboard_omnitest.html",
    "title": "Dashboard Omnitest X University",
    "section": "",
    "text": "Dashboard Site"
  },
  {
    "objectID": "projects/2025_05_03_dashboard_omnitest.html#introduction",
    "href": "projects/2025_05_03_dashboard_omnitest.html#introduction",
    "title": "Dashboard Omnitest X University",
    "section": "Introduction",
    "text": "Introduction\nThis dashboard provides analytics and insights for Omnitest data X University student data.Omnitest or OMNI Personality Inventory is a self-report questionnaire designed for use with adolescents and adults between 18 and 74 years of age. This is a broad measure that assesses a wide range of personality traits, including both normal and abnormal characteristics. It consists of 375 items and 25 scales for normal traits and 10 scales for abnormal traits, along with two validity scales and seven broad scales."
  },
  {
    "objectID": "projects/2025_05_03_dashboard_omnitest.html#tools",
    "href": "projects/2025_05_03_dashboard_omnitest.html#tools",
    "title": "Dashboard Omnitest X University",
    "section": "Tools",
    "text": "Tools\nThe dashboard leverages several key Tools:\n\nR: For data wrangling, statistical analysis, and visualization\nQuarto: For creating the interactive dashboard framework\nplotly: For interactive charts and visualizations\nDT: For interactive data tables"
  },
  {
    "objectID": "projects/2025_05_03_dashboard_omnitest.html#tutorial",
    "href": "projects/2025_05_03_dashboard_omnitest.html#tutorial",
    "title": "Dashboard Omnitest X University",
    "section": "Tutorial",
    "text": "Tutorial\nThe tutorial will be created soon."
  },
  {
    "objectID": "projects/End_to_end_ML.html",
    "href": "projects/End_to_end_ML.html",
    "title": "End To End Machine Learning (R, Python, Quarto, Shiny, GitHub, Posit Connect)",
    "section": "",
    "text": "App R   App R Code   App Python   App Python Code\nTutorial ini akan membahas tentang bagaimana cara membuat aplikasi machine learning sederhana dengan menggunakan kombinasi R, Python, Quarto, Shiny, GitHub, dan Posit Connect Cloud. Tutorial ini merupakan gambaran proyek end-to-end machine learning mulai dari pengolahan data, pemodelan, hingga deployment ke dalam aplikasi yang dapat diakses oleh pengguna (user). Tutorial ini sangat sederhana dengan tujuan menunjukkan proses end-to-end machine learning yang pada kenyataannya cukup kompleks. Dalam tutorial ini, proses dibuat sederhana untuk menunjukkan titik awal dan akhir. Banyak proses yang dipersingkat demi efisiensi tutorial. Sebagai catatan, tutorial ini dibuat untuk intermediate user yang sudah memahami dasar-dasar beberapa tools yang digunakan.\nSecara singkat, berikut penjelasan kegunaan beberapa tools yang digunakan dalam tutorial ini:"
  },
  {
    "objectID": "projects/End_to_end_ML.html#langkah-1-trainingfitting-model-machine-learning-dengan-r-atau-python",
    "href": "projects/End_to_end_ML.html#langkah-1-trainingfitting-model-machine-learning-dengan-r-atau-python",
    "title": "End To End Machine Learning (R, Python, Quarto, Shiny, GitHub, Posit Connect)",
    "section": "Langkah 1: Training/Fitting Model Machine Learning dengan R atau Python",
    "text": "Langkah 1: Training/Fitting Model Machine Learning dengan R atau Python\nPada tuorial ini, disajikan dua pilihan bahasa pemrograman untuk melakukan fitting model machine learning, yaitu R dan Python. Anda dapat memilih salah satu bahasa pemrograman yang paling Anda kuasai.\nWorkflow machine learning cukup panjang dan kompleks. Pada tutorial ini aakan disajikan langkah-langkah yang paling umum dilakukan dalam machine learning. Detil tentang workflow machine learning dapat dilihat di sini.\n\nData\nDataset yang digunakan dalam tutorial ini adalah dataset penyakit jantung dari UCI Machine Learning Repository. Dataset ini berisi informasi tentang pasien dengan penyakit jantung koroner (CAD). Dataset ini dapat diunduh dari sini. Dataset ini juga sudah disertakan dalam folder data pada repositori GitHub.\n\ndf1 &lt;- read.csv(\"data/heart.csv\")\nhead(df1)\n\n  age sex cp trestbps choi fbs restecg thalach exang oldpeak slope ca thai num\n1  63   1  1      145  233   1       2     150     0     2.3     3  0    6   0\n2  67   1  4      160  286   0       2     108     1     1.5     2  3    3   1\n3  67   1  4      120  229   0       2     129     1     2.6     2  2    7   1\n4  37   1  3      130  250   0       0     187     0     3.5     3  0    3   0\n5  41   0  2      130  204   0       2     172     0     1.4     1  0    3   0\n6  56   1  2      120  236   0       0     178     0     0.8     1  0    3   0\n\n\n\nKeterangan Data\n\n\n\n\n\n\n\n\n\n\nNo.\nVariabel\nTipe / Satuan\nNilai /Kategori (Ter­definisi)\nArti Klinis singkat\n\n\n\n\n1\nage\nNumerik (tahun)\n± 29 – 77\nUsia pasien; faktor risiko kardiovaskular meningkat seiring bertambahnya usia.\n\n\n2\nsex\nBiner\n1 = laki‑laki, 0 = perempuan\nPerbedaan hormonal & anatomi memengaruhi kejadian penyakit jantung.\n\n\n3\ncp\nKategorik (1‑4)\n1 = angina tipikal 2 = angina atypical 3 = nyeri non‑angina 4 = asimptomatik\nJenis nyeri membantu menilai risiko penyakit arteri koroner.\n\n\n4\ntrestbps\nNumerik (mm Hg)\n± 90 – 200\nTekanan darah istirahat tinggi meningkatkan beban jantung.\n\n\n5\nchol\nNumerik (mg/dL)\n± 120 – 564\nKadar kolesterol tinggi berkaitan dengan aterosklerosis.\n\n\n6\nfbs\nBiner\n1 = gula puasa &gt; 120 mg/dL, 0 = tidak\nHiperglikemia kronis mempercepat kerusakan pembuluh darah.\n\n\n7\nrestecg\nKategorik (0‑2)\n0 = normal 1 = ST‑T abnormal 2 = LVH\nAbnormalitas EKG istirahat menandakan gangguan listrik jantung awal.\n\n\n8\nthalach\nNumerik (bpm)\n± 60 – 202\nDenyut jantung maksimum saat tes; indikasi kapasitas aerobik & iskemia.\n\n\n9\nexang\nBiner\n1 = angina saat latihan, 0 = tidak\nNyeri dada saat treadmill → iskemia terinduksi stres.\n\n\n10\noldpeak\nNumerik (mV)\n0.0 – 6.2\nBesar depresi ST; semakin besar → iskemia lebih berat.\n\n\n11\nslope\nKategorik (1‑3)\n1 = up‑sloping 2 = flat 3 = down‑sloping\nDown‑sloping paling berkorelasi dengan CAD.\n\n\n12\nca\nNumerik diskret (0‑3)\n0, 1, 2, 3\nJumlah pembuluh besar tersumbat; indikator keparahan.\n\n\n13\nthal\nKategorik (3/6/7)\n3 = normal 6 = defek tetap 7 = defek reversibel\nDefek reversibel → iskemia; defek tetap → infark lama.\n\n\n14\nnum\nBiner (label)\n0 = &lt; 50 % stenosis 1 = ≥ 50 % stenosis\nDiagnosa penyakit arteri koroner signifikan (target model).\n\n\n\n\ndf1 &lt;- transform(\n  df1,\n  age=as.integer(age),\n  sex=as.factor(sex),\n  cp=as.factor(cp),\n  trestbps=as.integer(trestbps),\n  choi=as.integer(choi),\n  fbs=as.factor(fbs),\n  restecg=as.factor(restecg),\n  thalach=as.integer(thalach),\n  exang=as.factor(exang),\n  oldpeak=as.numeric(oldpeak),\n  slope=as.factor(slope),\n  ca=factor(ca,labels=c(\"0\",\"1\",\"2\",\"3\")),\n  thai=factor(thai,labels=c(\"3\",\"6\",\"7\")),\n  num=as.factor(num)\n)\n\nhead(df1)\n\n  age sex cp trestbps choi fbs restecg thalach exang oldpeak slope ca thai num\n1  63   1  1      145  233   1       2     150     0     2.3     3  0    6   0\n2  67   1  4      160  286   0       2     108     1     1.5     2  3    3   1\n3  67   1  4      120  229   0       2     129     1     2.6     2  2    7   1\n4  37   1  3      130  250   0       0     187     0     3.5     3  0    3   0\n5  41   0  2      130  204   0       2     172     0     1.4     1  0    3   0\n6  56   1  2      120  236   0       0     178     0     0.8     1  0    3   0\n\n\n\n\n\nFitting Model di R\nCatatan: EDA dan Hyperparameter tuning tidak ditampilkan di sini. Kedepannya, EDA dan Hyperparameter tuning perlu dilakukan karena bagian dari proses pemodelan machine learning yang dapat meningkatkan akurasi model. Namun, untuk keperluan tutorial ini, EDA dan Hyperparameter tuning tidak ditampilkan.\nDi R, kita dapat menggunakan package tidymodels untuk fitting model. Package ini merupakan koleksi dari beberapa package yang saling terintegrasi untuk memudahkan kita dalam melakukan pemodelan machine learning.\nJika tertarik belajar lebih lanjut tentang tidymodels bisa membuka sumber-sumber berikut:\n\nBuku Tidy Modeling with R\nWebsite Learning tidymodels\nYoutube Playlist TidyX - tidymodels\n\n\nlibrary(tidymodels)\n\n\nAlgoritma Regresi Logistik\n\n# ────────────────────────────────────────────────────────────────────────────────\n# 1. Pustaka & reproducibility\nset.seed(26)\n\n# ────────────────────────────────────────────────────────────────────────────────\n# 2. Train–test split (stratified)\n# ────────────────────────────────────────────────────────────────────────────────\nsplit_obj  &lt;- initial_split(df1, prop = 0.75, strata = num)   # num = label biner\ntrain_data &lt;- training(split_obj)\ntest_data  &lt;- testing(split_obj)\n\n# ────────────────────────────────────────────────────────────────────────────────\n# 3. Recipe (praproses fitur)\n# ────────────────────────────────────────────────────────────────────────────────\nheart_rec &lt;- recipe(num ~ ., data = train_data) %&gt;% \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %&gt;%  # encode factor → 0/1\n  step_zv(all_predictors())                                # hilangkan variabel var. 0\n# *Jika data sudah siap, cukup recipe(num ~ ., data = train_data)\n\n# ────────────────────────────────────────────────────────────────────────────────\n# 4. Spesifikasi model regresi logistik\n# ────────────────────────────────────────────────────────────────────────────────\nlog_spec &lt;- \n  logistic_reg() %&gt;%        # default = tanpa regularisasi, link logit\n  set_engine(\"glm\") %&gt;%     # backend base-R glm()\n  set_mode(\"classification\")\n\n# ────────────────────────────────────────────────────────────────────────────────\n# 5. Workflow\n# ────────────────────────────────────────────────────────────────────────────────\nlog_wf &lt;- workflow() %&gt;% \n  add_recipe(heart_rec) %&gt;% \n  add_model(log_spec)\n\n# ────────────────────────────────────────────────────────────────────────────────\n# 6. Fit model\n# ────────────────────────────────────────────────────────────────────────────────\nlog_fit &lt;- fit(log_wf, data = train_data)\n\n# ────────────────────────────────────────────────────────────────────────────────\n# 7. Prediksi & evaluasi\n# ────────────────────────────────────────────────────────────────────────────────\nlog_preds &lt;- predict(log_fit, test_data, type = \"prob\") %&gt;%   # probabilitas kelas 1\n  bind_cols(predict(log_fit, test_data, type = \"class\")) %&gt;%  # label hasil klasifikasi\n  bind_cols(test_data %&gt;% select(num))\n\n# Metrik umum\nmetrics(log_preds, truth = num, estimate = .pred_class)[1,] # akurasi\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.829\n\n# Confusion matrix\nconf_mat(log_preds, truth = num, estimate = .pred_class)\n\n          Truth\nPrediction  0  1\n         0 37  9\n         1  4 26\n\n# ────────────────────────────────────────────────────────────────────────────────\n# 8. Simpan model\n# ────────────────────────────────────────────────────────────────────────────────\nsaveRDS(log_fit, \"results/logreg_R.rda\")\n\nAkurasi dari model regresi logistik yang dihasilkan adalah 0.828. Model ini sudah disimpan dalam bentuk file RDS dengan nama logreg_R.rda. File ini dapat digunakan untuk memprediksi data baru.\n\n\nAlgoritma Random Forest\n\n# ── 1. Pustaka & reproducibility ───────────────────────────────────────────────\nset.seed(26)\n\n# ── 2. Train–test split --------------------------------------------------------\nsplit_obj   &lt;- initial_split(df1, prop = 0.75, strata = num)\ntrain_data  &lt;- training(split_obj)\ntest_data   &lt;- testing(split_obj)\n\n# ── 3. Recipe (opsional: praproses) -------------------------------------------\nheart_rec &lt;- \n  recipe(num ~ ., data = train_data) |&gt;\n  step_dummy(all_nominal_predictors(), one_hot = TRUE) |&gt;   # encode faktor\n  step_zv(all_predictors())                                # buang variabel var. 0\n\n# ── 4. Spesifikasi model -------------------------------------------------------\nrf_spec &lt;- \n  rand_forest() |&gt;\n  set_engine(\"randomForest\") |&gt;\n  set_mode(\"classification\")\n\n# ── 5. Workflow ----------------------------------------------------------------\nrf_wf &lt;- workflow() |&gt;\n  add_recipe(heart_rec) |&gt;\n  add_model(rf_spec)\n\n# ── 6. Fit model ---------------------------------------------------------------\nrf_fit &lt;- fit(rf_wf, data = train_data)\n\n# ── 7. Prediksi & evaluasi -----------------------------------------------------\nrf_preds &lt;- predict(rf_fit, test_data) |&gt; \n            bind_cols(test_data |&gt; select(num))\n\nmetrics(rf_preds, truth = num, estimate = .pred_class)[1,] # akurasi\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.842\n\n# Confusion matrix\nconf_mat(rf_preds, truth = num, estimate = .pred_class)\n\n          Truth\nPrediction  0  1\n         0 38  9\n         1  3 26\n\n# ── 8. Simpan model --------------------------------------------\nsaveRDS(rf_fit, \"results/rf_R.rda\")\n\nAkurasi dari model random forest yang dihasilkan adalah 0.842. Model ini sudah disimpan dalam bentuk file RDS dengan nama rf_R.rda. File ini dapat digunakan untuk memprediksi data baru.\nModel Terbaik\nModel terbaik dari kedua algoritma yang digunakan adalah model random forest. Model ini yang akan dideploy ke dalam aplikasi Shiny.\n\n\n\nFitting Model di Python\nDi Python, kita dapat menggunakan package scikit-learn untuk fitting model. Package ini merupakan package yang paling banyak digunakan untuk pemodelan machine learning di Python.\nJika tertarik belajar lebih lanjut tentang scikit-learn bisa membuka sumber-sumber berikut:\n\nBuku Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\nWebsite Scikit-learn\nYoutube Playlist Scikit-learn\n\n\n# Load reticulate package\n# Pakckage ini digunakan untuk menghubungkan R dengan Python\nlibrary(reticulate)\n\n\nimport pandas as pd\nimport numpy as np\n\n# Load data\ndf1 = pd.read_csv(\"data/heart.csv\")\ndf1.head()\n\n   age  sex  cp  trestbps  choi  fbs  ...  exang  oldpeak  slope  ca  thai  num\n0   63    1   1       145   233    1  ...      0      2.3      3   0     6    0\n1   67    1   4       160   286    0  ...      1      1.5      2   3     3    1\n2   67    1   4       120   229    0  ...      1      2.6      2   2     7    1\n3   37    1   3       130   250    0  ...      0      3.5      3   0     3    0\n4   41    0   2       130   204    0  ...      0      1.4      1   0     3    0\n\n[5 rows x 14 columns]\n\n\n\nimport pandas as pd\n\n# ---- fungsi utilitas -------------------------------------------------------\ndef as_category(series, categories=None):\n    \"\"\"\n    Ubah series ke pandas.Categorical.\n    Jika 'categories' diberikan, urutannya disetel eksplisit (mirip labels R).\n    \"\"\"\n    if categories is not None:\n        return pd.Categorical(series, categories=categories, ordered=False)\n    return series.astype(\"category\")\n\n\n# ---- transformasi tipe -----------------------------------------------------\ndf1 = (\n    df1\n      .assign(\n          age      = lambda x: x[\"age\"].astype(\"int32\"),\n          sex      = lambda x: as_category(x[\"sex\"]),\n          cp       = lambda x: as_category(x[\"cp\"]),\n          trestbps = lambda x: x[\"trestbps\"].astype(\"int32\"),\n          choi     = lambda x: x[\"choi\"].astype(\"int32\"),   # ganti 'choi' → 'chol' bila perlu\n          fbs      = lambda x: as_category(x[\"fbs\"]),\n          restecg  = lambda x: as_category(x[\"restecg\"]),\n          thalach  = lambda x: x[\"thalach\"].astype(\"int32\"),\n          exang    = lambda x: as_category(x[\"exang\"]),\n          oldpeak  = lambda x: pd.to_numeric(x[\"oldpeak\"], errors=\"coerce\"),\n          slope    = lambda x: as_category(x[\"slope\"]),\n          ca       = lambda x: as_category(x[\"ca\"],   categories=[0, 1, 2, 3]),\n          thai     = lambda x: as_category(x[\"thai\"], categories=[3, 6, 7]),\n          num      = lambda x: as_category(x[\"num\"])\n      )\n)\n\n# ---- lihat hasil -----------------------------------------------------------\nprint(df1.head())\n\n   age sex cp  trestbps  choi fbs  ... exang  oldpeak slope  ca thai num\n0   63   1  1       145   233   1  ...     0      2.3     3   0    6   0\n1   67   1  4       160   286   0  ...     1      1.5     2   3    3   1\n2   67   1  4       120   229   0  ...     1      2.6     2   2    7   1\n3   37   1  3       130   250   0  ...     0      3.5     3   0    3   0\n4   41   0  2       130   204   0  ...     0      1.4     1   0    3   0\n\n[5 rows x 14 columns]\n\nprint(df1.dtypes)\n\nage            int32\nsex         category\ncp          category\ntrestbps       int32\nchoi           int32\nfbs         category\nrestecg     category\nthalach        int32\nexang       category\noldpeak      float64\nslope       category\nca          category\nthai        category\nnum         category\ndtype: object\n\n\n\nAlgoritma Regresi Logistik\n\n# ───────────────────────────────────────────────────────────────────────────────\n# 0. Pustaka & reproducibility\n# ───────────────────────────────────────────────────────────────────────────────\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport joblib          # untuk simpan / load model\nnp.random.seed(26)\n\n# ───────────────────────────────────────────────────────────────────────────────\n# 1. Train–test split  (stratified, 75 % train)\n# ───────────────────────────────────────────────────────────────────────────────\nX = df1.drop(columns=[\"num\"])\ny = df1[\"num\"]\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    train_size=0.75,\n    stratify=y,\n    random_state=26\n)\n\n# ───────────────────────────────────────────────────────────────────────────────\n# 2. Pre‑processing (recipe setara)\n#    • One‑hot seluruh kolom kategorik\n#    • Buang prediktor varian 0 (mirip step_zv)\n# ───────────────────────────────────────────────────────────────────────────────\ncat_cols  = X.select_dtypes(include=[\"object\", \"category\"]).columns\nnum_cols  = X.select_dtypes(include=[\"number\"]).columns\n\npreprocess = ColumnTransformer(\n    transformers=[\n        (\"cat\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"), cat_cols),\n        (\"num\", \"passthrough\", num_cols)\n    ]\n)\n\n# ───────────────────────────────────────────────────────────────────────────────\n# 3. Spesifikasi model + Workflow (Pipeline)\n# ───────────────────────────────────────────────────────────────────────────────\nlog_pipeline = Pipeline(steps=[\n    (\"preprocess\", preprocess),\n    (\"nzv\", VarianceThreshold(threshold=0.0)),           # hilangkan varian 0\n    (\"model\", LogisticRegression())\n])\n\n# ───────────────────────────────────────────────────────────────────────────────\n# 4. Fit model\n# ───────────────────────────────────────────────────────────────────────────────\nlog_pipeline.fit(X_train, y_train)\n\nPipeline(steps=[('preprocess',\n                 ColumnTransformer(transformers=[('cat',\n                                                  OneHotEncoder(drop='first',\n                                                                handle_unknown='ignore'),\n                                                  Index(['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thai'], dtype='object')),\n                                                 ('num', 'passthrough',\n                                                  Index(['age', 'trestbps', 'choi', 'thalach', 'oldpeak'], dtype='object'))])),\n                ('nzv', VarianceThreshold()), ('model', LogisticRegression())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.Pipeline?Documentation for PipelineiFittedPipeline(steps=[('preprocess',\n                 ColumnTransformer(transformers=[('cat',\n                                                  OneHotEncoder(drop='first',\n                                                                handle_unknown='ignore'),\n                                                  Index(['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thai'], dtype='object')),\n                                                 ('num', 'passthrough',\n                                                  Index(['age', 'trestbps', 'choi', 'thalach', 'oldpeak'], dtype='object'))])),\n                ('nzv', VarianceThreshold()), ('model', LogisticRegression())]) preprocess: ColumnTransformer?Documentation for preprocess: ColumnTransformerColumnTransformer(transformers=[('cat',\n                                 OneHotEncoder(drop='first',\n                                               handle_unknown='ignore'),\n                                 Index(['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thai'], dtype='object')),\n                                ('num', 'passthrough',\n                                 Index(['age', 'trestbps', 'choi', 'thalach', 'oldpeak'], dtype='object'))]) catIndex(['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thai'], dtype='object') OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(drop='first', handle_unknown='ignore') numIndex(['age', 'trestbps', 'choi', 'thalach', 'oldpeak'], dtype='object') passthroughpassthrough VarianceThreshold?Documentation for VarianceThresholdVarianceThreshold() LogisticRegression?Documentation for LogisticRegressionLogisticRegression() \n\n# ───────────────────────────────────────────────────────────────────────────────\n# 5. Prediksi & evaluasi\n# ───────────────────────────────────────────────────────────────────────────────\ny_pred  = log_pipeline.predict(X_test)\ny_prob  = log_pipeline.predict_proba(X_test)[:, 1]       # prob kelas 1 (≥ 50 % stenosis)\n\nacc = accuracy_score(y_test, y_pred)\ncm  = confusion_matrix(y_test, y_pred)\n\nprint(f\"Accuracy : {acc:.3f}\")\n\nAccuracy : 0.787\n\nprint(\"Confusion matrix:\\n\", cm)\n\nConfusion matrix:\n [[32  8]\n [ 8 27]]\n\n# ───────────────────────────────────────────────────────────────────────────────\n# 6. Simpan model\n# ───────────────────────────────────────────────────────────────────────────────\njoblib.dump(log_pipeline, \"results/logreg_py.joblib\")   # simpan\n\n['results/logreg_py.joblib']\n\n\n\n\nAlgoritma Random Forest\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n# reproducibility\nnp.random.seed(26)\n\n# ── 1. Split data (stratified 75 % train) ──────────────────────────────────────\nX = df1.drop(columns=[\"num\"])\ny = df1[\"num\"]\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    train_size=0.75,\n    stratify=y,\n    random_state=26\n)\n\n# ── 2. Pre‑processing ----------------------------------------------------------\ncat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\nnum_cols = X.select_dtypes(include=[\"number\"]).columns\n\npreprocess = ColumnTransformer(\n    transformers=[\n        (\"cat\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"), cat_cols),\n        (\"num\", \"passthrough\", num_cols)\n    ]\n)\n\n# ── 3. Spesifikasi Random Forest -----------------------------------\nrf_model = RandomForestClassifier(\n    random_state=26,\n    n_jobs=-1              # gunakan seluruh core\n)\n\n# ── 4. Pipeline workflow -------------------------------------------------------\nrf_pipeline = Pipeline(steps=[\n    (\"preprocess\", preprocess),\n    (\"nzv\", VarianceThreshold(threshold=0.0)),   # buang varian 0\n    (\"model\", rf_model)\n])\n\n# ── 5. Fit model ---------------------------------------------------------------\nrf_pipeline.fit(X_train, y_train)\n\nPipeline(steps=[('preprocess',\n                 ColumnTransformer(transformers=[('cat',\n                                                  OneHotEncoder(drop='first',\n                                                                handle_unknown='ignore'),\n                                                  Index(['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thai'], dtype='object')),\n                                                 ('num', 'passthrough',\n                                                  Index(['age', 'trestbps', 'choi', 'thalach', 'oldpeak'], dtype='object'))])),\n                ('nzv', VarianceThreshold()),\n                ('model', RandomForestClassifier(n_jobs=-1, random_state=26))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.Pipeline?Documentation for PipelineiFittedPipeline(steps=[('preprocess',\n                 ColumnTransformer(transformers=[('cat',\n                                                  OneHotEncoder(drop='first',\n                                                                handle_unknown='ignore'),\n                                                  Index(['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thai'], dtype='object')),\n                                                 ('num', 'passthrough',\n                                                  Index(['age', 'trestbps', 'choi', 'thalach', 'oldpeak'], dtype='object'))])),\n                ('nzv', VarianceThreshold()),\n                ('model', RandomForestClassifier(n_jobs=-1, random_state=26))]) preprocess: ColumnTransformer?Documentation for preprocess: ColumnTransformerColumnTransformer(transformers=[('cat',\n                                 OneHotEncoder(drop='first',\n                                               handle_unknown='ignore'),\n                                 Index(['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thai'], dtype='object')),\n                                ('num', 'passthrough',\n                                 Index(['age', 'trestbps', 'choi', 'thalach', 'oldpeak'], dtype='object'))]) catIndex(['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thai'], dtype='object') OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(drop='first', handle_unknown='ignore') numIndex(['age', 'trestbps', 'choi', 'thalach', 'oldpeak'], dtype='object') passthroughpassthrough VarianceThreshold?Documentation for VarianceThresholdVarianceThreshold() RandomForestClassifier?Documentation for RandomForestClassifierRandomForestClassifier(n_jobs=-1, random_state=26) \n\n# ── 6. Evaluasi ---------------------------------------------------------------\ny_pred = rf_pipeline.predict(X_test)\nacc    = accuracy_score(y_test, y_pred)\ncm     = confusion_matrix(y_test, y_pred)\n\nprint(f\"Accuracy : {acc:.3f}\")\n\nAccuracy : 0.773\n\nprint(\"Confusion matrix:\\n\", cm)\n\nConfusion matrix:\n [[33  7]\n [10 25]]\n\n# ── 7. Simpan model -----------------------------------------------------------\njoblib.dump(rf_pipeline, \"results/rf_py.joblib\")\n\n['results/rf_py.joblib']"
  },
  {
    "objectID": "projects/End_to_end_ML.html#langkah-2-deploy-model-dan-membuat-aplikasi-shiny",
    "href": "projects/End_to_end_ML.html#langkah-2-deploy-model-dan-membuat-aplikasi-shiny",
    "title": "End To End Machine Learning (R, Python, Quarto, Shiny, GitHub, Posit Connect)",
    "section": "Langkah 2: Deploy Model dan Membuat Aplikasi Shiny",
    "text": "Langkah 2: Deploy Model dan Membuat Aplikasi Shiny\nSetelah model dilatih, langkah selanjutnya adalah mendepoy model dan membuat aplikasi Shiny. Model yang dilatih di R disimpan dalam bentuk file RDS, sedangkan model yang dilatih di Python disimpan dalam bentuk file joblib. File-file ini akan digunakan untuk memprediksi data baru.\nAplikasi Shiny adalah aplikasi web interaktif yang dibuat dengan menggunakan bahasa pemrograman R atau Python. Aplikasi ini dapat digunakan untuk memprediksi data baru dengan menggunakan model yang sudah dilatih. Aplikasi Shiny dapat diakses oleh pengguna melalui web browser.\nJika tertarik belajar lebih lanjut tentang Shiny bisa membuka sumber-sumber berikut:\n\nBuku Mastering Shiny\nWebsite Shiny\n\nKode aplikasi Shiny untuk tutorial dapat dilihat pada repositori GitHub.\n  App R Code  \n  App Python Code \nGambaran model yang sudah didepoy ke dalam aplikasi Shiny dapat dilihat pada berikut (App R)\n\nPengguna dapat memasukkan data baru sesuai dengan kolom fitur yang ada pada dataset. Setelah itu, pengguna dapat menekan tombol “Submit” untuk mendapatkan hasil prediksi dari model."
  },
  {
    "objectID": "projects/End_to_end_ML.html#langkah-3-buat-repositori-github-untuk-aplikasi-shiny",
    "href": "projects/End_to_end_ML.html#langkah-3-buat-repositori-github-untuk-aplikasi-shiny",
    "title": "End To End Machine Learning (R, Python, Quarto, Shiny, GitHub, Posit Connect)",
    "section": "Langkah 3: Buat Repositori GitHub untuk Aplikasi Shiny",
    "text": "Langkah 3: Buat Repositori GitHub untuk Aplikasi Shiny\nBuat repositori GitHub untuk menyimpan kode sumber dari aplikasi Shiny yang sudah dibuat. Repositori ini akan digunakan untuk menyimpan kode sumber dari aplikasi Shiny."
  },
  {
    "objectID": "projects/End_to_end_ML.html#langkah-4-publikasi-aplikasi-shiny-ke-posit-connect-cloud",
    "href": "projects/End_to_end_ML.html#langkah-4-publikasi-aplikasi-shiny-ke-posit-connect-cloud",
    "title": "End To End Machine Learning (R, Python, Quarto, Shiny, GitHub, Posit Connect)",
    "section": "Langkah 4: Publikasi Aplikasi Shiny ke Posit Connect Cloud",
    "text": "Langkah 4: Publikasi Aplikasi Shiny ke Posit Connect Cloud\nPublikasikan aplikasi Shiny ke Posit Connect Cloud agar dapat diakses oleh pengguna (user). Publikasi melalui Posit Connect Cloud sangat mudah dilakukan.\n\nBuat akun Posit Connect Cloud di sini\nPilih framework yang digunakan. Terdapat beberapa pilihan salah satunya adalah Shiny. Kita mempublikasikan aplikasi Shiny ke dalam Posit Connect Cloud melalui github. Pilih GitHub sebagai sumber aplikasi yang akan dipublikasikan. Sehingga kita perlu menghubungkan akun GitHub kita ke dalam Posit Connect Cloud.\n\n \nSekarang kita sudah bisa mempublikasikan dan membagikan aplikasi machine learning kita ke pengguna lain. Selamat mencoba!"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "\nHi! I’m Deri Siswara 👋\n",
    "section": "",
    "text": "Hi! I’m Deri Siswara 👋\n\n\nWelcome to my portfolio garden. I am currently an Adjunct Lecturer in the Department of Data Science at the Perbanas Institute. I graduated from IPB University in 2020 with a B.Ec. in Islamic Economics and in 2024 with an M.Sc. in Statistics and Data Science. I enjoy working with data using R and Python. I’m also proficient in various software tools for data analysis. I’m open to collaborations, projects, or new opportunities.\n\n\nTeaching ⤵️\nSelected list of teaching activities and workshops.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Quarto\n\n\n\nTalks\n\nQuarto\n\n\n\nSlides and code exercises for the introduction to Quarto.\n\n\n\nNov 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nRStudio Workshop 2025\n\n\n\nWorkshop\n\nR\n\nEconometrics\n\nStatistics\n\n\n\nPeningkatan Research Quality dengan RStudio\n\n\n\nMay 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning\n\n\n\nPython\n\nMachine Learning\n\n\n\nSlides and materials for the Machine Learning course.\n\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nBank Indonesia Data Anomalies Study\n\n\n\nWorkshop\n\nR\n\n\n\nSlides and code exercise for the study of detecting anomalies in Bank Indonesia data using statistical approaches.\n\n\n\nJun 1, 2024\n\n\n\n\n\n\nNo matching items\n Back to top",
    "crumbs": [
      "Teaching"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nHi! I’m Deri Siswara 👋\n",
    "section": "",
    "text": "Hi! I’m Deri Siswara 👋\n\n\nWelcome to my portfolio garden. Research/Data Analyst with a background in Statistics and Economics. Experienced in survey design, creating dashboards, impact assessment, econometric modeling, and teaching. Worked on various projects across multiple sectors, bringing unique and diverse perspectives to problem-solving. I’m open to collaborations, projects, or new opportunities.\n\n\nProjects ⤵️\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDashboard Omnitest X University\n\n\n\nVisualization\n\nDashboard\n\nR\n\n\n\nThis dashboard is created using R and Quarto.\n\n\n\n\n\nMay 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nEnd To End Machine Learning (R, Python, Quarto, Shiny, GitHub, Posit Connect)\n\n\n\nPython\n\nR\n\nMachine Learning\n\n\n\nTutorial on building a machine learning application using R, Python, Quarto, Shiny, GitHub, and Posit Connect\n\n\n\n\n\nApr 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nApplication of Econometric Models with RStudio\n\n\n\nR\n\nBook\n\nEconometrics\n\n\n\nThe code version of Application of Econometric Models with RStudio, a book released in 2023 by IPB Press. The book was written by Muhammad Firdaus, Tony Irawan, Fahmi Salam Ahmad, Hermanto Siregar, Deri Siswara, and Rodi Jakariya.\n\n\n\n\n\nFeb 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nQuantitative Methods with RStudio: Application for Management and Business Research\n\n\n\nR\n\nBook\n\nMultivariate / Quantitative Methods\n\n\n\nThe code version of Quantitative Methods with RStudio: Application for Management and Business Research, a book released in 2024 by IPB Press. The book was written by Muhammad Firdaus, Farit M Afendi, Deri Siswara, and Nafisa Berliana Indah Pratiwi.\n\n\n\n\n\nFeb 16, 2024\n\n\n\n\n\nNo matching items\n\n  \n\n Back to top",
    "crumbs": [
      "Projects"
    ]
  },
  {
    "objectID": "teaching/quarto.html",
    "href": "teaching/quarto.html",
    "title": "Introduction to Quarto",
    "section": "",
    "text": "Have a chance for sharing about the Quarto framework in the BelajaR community. The slides and code exercises are provided below.\n\n\nDocumentation:\n\n\n\n\n Back to topCitationBibTeX citation:@online{siswara2025,\n  author = {Siswara, Deri},\n  title = {Introduction to {Quarto}},\n  date = {2025-11-05},\n  url = {https://derisiswara.org/teaching/quarto.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nSiswara, Deri. 2025. “Introduction to Quarto.” November 5,\n2025. https://derisiswara.org/teaching/quarto.html."
  },
  {
    "objectID": "teaching/workshop.html",
    "href": "teaching/workshop.html",
    "title": "RStudio Workshop 2025",
    "section": "",
    "text": "Workshop Material \n\n📆 Mei 6, 2025 // 10:00 - 16:30 WIB\n🏨 Gedung UNIFAC, Kampus UNJA Mendalo\nDocumentation:\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "cv/dericv/CHANGELOG.html",
    "href": "cv/dericv/CHANGELOG.html",
    "title": "Basic Resume Changelog",
    "section": "",
    "text": "Add font-size and author-font-size configuration options\n\n\n\nEmbarassing version bump\n\n\n\nBump typst version to 0.13.0 and above\n\n\n\nBump scienceicon dep to fix #21\n\n\n\nAdd option for consistent style of dates on upper right of components.\n\n\n\nUser can set posistion of author and personal info.\n\n\n\nAllow changing of page sizes from us-letter to other sizes, such as A4, for Non-US folks\n\n\n\nSupport orcid as a social link. Also fix contact-item’s prefix argument.\n\n\n\nModify to work with Typst version 0.12. Also extend projects function to be more robust.\n\n\n\nMake more resume fields optional (links in projects and certs)\n\n\n\nAllow for changing of fonts via initial configuration\n\n\n\nVersion bump because I’m stupid🐛\n\n\n\nMake resume fields optional\n\n\n\nInitial Release"
  },
  {
    "objectID": "cv/dericv/CHANGELOG.html#v0.2.8",
    "href": "cv/dericv/CHANGELOG.html#v0.2.8",
    "title": "Basic Resume Changelog",
    "section": "",
    "text": "Add font-size and author-font-size configuration options"
  },
  {
    "objectID": "cv/dericv/CHANGELOG.html#v0.2.7",
    "href": "cv/dericv/CHANGELOG.html#v0.2.7",
    "title": "Basic Resume Changelog",
    "section": "",
    "text": "Embarassing version bump"
  },
  {
    "objectID": "cv/dericv/CHANGELOG.html#v0.2.6",
    "href": "cv/dericv/CHANGELOG.html#v0.2.6",
    "title": "Basic Resume Changelog",
    "section": "",
    "text": "Bump typst version to 0.13.0 and above"
  },
  {
    "objectID": "cv/dericv/CHANGELOG.html#v0.2.5",
    "href": "cv/dericv/CHANGELOG.html#v0.2.5",
    "title": "Basic Resume Changelog",
    "section": "",
    "text": "Bump scienceicon dep to fix #21"
  },
  {
    "objectID": "cv/dericv/CHANGELOG.html#v0.2.4",
    "href": "cv/dericv/CHANGELOG.html#v0.2.4",
    "title": "Basic Resume Changelog",
    "section": "",
    "text": "Add option for consistent style of dates on upper right of components."
  },
  {
    "objectID": "cv/dericv/CHANGELOG.html#v0.2.3",
    "href": "cv/dericv/CHANGELOG.html#v0.2.3",
    "title": "Basic Resume Changelog",
    "section": "",
    "text": "User can set posistion of author and personal info."
  },
  {
    "objectID": "cv/dericv/CHANGELOG.html#v0.2.2",
    "href": "cv/dericv/CHANGELOG.html#v0.2.2",
    "title": "Basic Resume Changelog",
    "section": "",
    "text": "Allow changing of page sizes from us-letter to other sizes, such as A4, for Non-US folks"
  },
  {
    "objectID": "cv/dericv/CHANGELOG.html#v0.2.1",
    "href": "cv/dericv/CHANGELOG.html#v0.2.1",
    "title": "Basic Resume Changelog",
    "section": "",
    "text": "Support orcid as a social link. Also fix contact-item’s prefix argument."
  },
  {
    "objectID": "cv/dericv/CHANGELOG.html#v0.2.0",
    "href": "cv/dericv/CHANGELOG.html#v0.2.0",
    "title": "Basic Resume Changelog",
    "section": "",
    "text": "Modify to work with Typst version 0.12. Also extend projects function to be more robust."
  },
  {
    "objectID": "cv/dericv/CHANGELOG.html#v0.1.4",
    "href": "cv/dericv/CHANGELOG.html#v0.1.4",
    "title": "Basic Resume Changelog",
    "section": "",
    "text": "Make more resume fields optional (links in projects and certs)"
  },
  {
    "objectID": "cv/dericv/CHANGELOG.html#v0.1.3",
    "href": "cv/dericv/CHANGELOG.html#v0.1.3",
    "title": "Basic Resume Changelog",
    "section": "",
    "text": "Allow for changing of fonts via initial configuration"
  },
  {
    "objectID": "cv/dericv/CHANGELOG.html#v0.1.2",
    "href": "cv/dericv/CHANGELOG.html#v0.1.2",
    "title": "Basic Resume Changelog",
    "section": "",
    "text": "Version bump because I’m stupid🐛"
  },
  {
    "objectID": "cv/dericv/CHANGELOG.html#v0.1.1",
    "href": "cv/dericv/CHANGELOG.html#v0.1.1",
    "title": "Basic Resume Changelog",
    "section": "",
    "text": "Make resume fields optional"
  },
  {
    "objectID": "cv/dericv/CHANGELOG.html#v0.1.0",
    "href": "cv/dericv/CHANGELOG.html#v0.1.0",
    "title": "Basic Resume Changelog",
    "section": "",
    "text": "Initial Release"
  },
  {
    "objectID": "teaching/outliers.html",
    "href": "teaching/outliers.html",
    "title": "Bank Indonesia Data Anomalies Study",
    "section": "",
    "text": "This study was conducted over three days at Bank Indonesia. The aim of this study is to find parameters and methods to detect anomalies in daily transaction data, balance sheets, and other financial reports.\n\n\nDocumentation:"
  },
  {
    "objectID": "teaching/outliers.html#outlier-analysis",
    "href": "teaching/outliers.html#outlier-analysis",
    "title": "Bank Indonesia Data Anomalies Study",
    "section": "",
    "text": "This study was conducted over three days at Bank Indonesia. The aim of this study is to find parameters and methods to detect anomalies in daily transaction data, balance sheets, and other financial reports.\n\n\nDocumentation:"
  },
  {
    "objectID": "teaching/machine_learning.html#machine-learning-workflow",
    "href": "teaching/machine_learning.html#machine-learning-workflow",
    "title": "Machine Learning",
    "section": "2 Machine Learning Workflow",
    "text": "2 Machine Learning Workflow\n  Code Exercise 1   Code Exercise 2"
  },
  {
    "objectID": "teaching/machine_learning.html#linear-regression-and-variable-selection-techniques-subset-selection",
    "href": "teaching/machine_learning.html#linear-regression-and-variable-selection-techniques-subset-selection",
    "title": "Machine Learning",
    "section": "3 Linear Regression and Variable Selection Techniques: Subset-Selection",
    "text": "3 Linear Regression and Variable Selection Techniques: Subset-Selection\n  Code Exercise"
  },
  {
    "objectID": "teaching/machine_learning.html#linear-regression-and-variable-selection-techniques-shrinkage-methods-ridge-lasso-elastic-net",
    "href": "teaching/machine_learning.html#linear-regression-and-variable-selection-techniques-shrinkage-methods-ridge-lasso-elastic-net",
    "title": "Machine Learning",
    "section": "4 Linear Regression and Variable Selection Techniques: Shrinkage Methods (Ridge, Lasso, Elastic Net)",
    "text": "4 Linear Regression and Variable Selection Techniques: Shrinkage Methods (Ridge, Lasso, Elastic Net)\n  Code Exercise"
  },
  {
    "objectID": "teaching/machine_learning.html#nonlinear-regression",
    "href": "teaching/machine_learning.html#nonlinear-regression",
    "title": "Machine Learning",
    "section": "5 Nonlinear Regression",
    "text": "5 Nonlinear Regression\n  Code Exercise"
  },
  {
    "objectID": "teaching/machine_learning.html#decision-tree-regression",
    "href": "teaching/machine_learning.html#decision-tree-regression",
    "title": "Machine Learning",
    "section": "6 Decision Tree Regression",
    "text": "6 Decision Tree Regression\n  Code Exercise"
  },
  {
    "objectID": "teaching/machine_learning.html#random-forest-regression",
    "href": "teaching/machine_learning.html#random-forest-regression",
    "title": "Machine Learning",
    "section": "7 Random Forest Regression",
    "text": "7 Random Forest Regression\n  Code Exercise"
  },
  {
    "objectID": "teaching/machine_learning.html#logistic-regression",
    "href": "teaching/machine_learning.html#logistic-regression",
    "title": "Machine Learning",
    "section": "8 Logistic Regression",
    "text": "8 Logistic Regression\n  Code Exercise 1 \n  Code Exercise 2"
  },
  {
    "objectID": "teaching/machine_learning.html#k-nearest-neighbors-support-vector-machine-and-bayesian-classifier",
    "href": "teaching/machine_learning.html#k-nearest-neighbors-support-vector-machine-and-bayesian-classifier",
    "title": "Machine Learning",
    "section": "9 K-Nearest Neighbors, Support Vector Machine, and Bayesian Classifier",
    "text": "9 K-Nearest Neighbors, Support Vector Machine, and Bayesian Classifier"
  },
  {
    "objectID": "teaching/machine_learning.html#xgboost-dan-isu-dalam-pemodelan-klasifikasi",
    "href": "teaching/machine_learning.html#xgboost-dan-isu-dalam-pemodelan-klasifikasi",
    "title": "Machine Learning",
    "section": "10 XGBoost dan Isu Dalam Pemodelan Klasifikasi",
    "text": "10 XGBoost dan Isu Dalam Pemodelan Klasifikasi\n  Code Exercise"
  },
  {
    "objectID": "teaching/machine_learning.html#unsupervised-learning-clustering",
    "href": "teaching/machine_learning.html#unsupervised-learning-clustering",
    "title": "Machine Learning",
    "section": "11 Unsupervised Learning: Clustering",
    "text": "11 Unsupervised Learning: Clustering\n  Code Exercise"
  },
  {
    "objectID": "teaching/machine_learning.html#neural-networks",
    "href": "teaching/machine_learning.html#neural-networks",
    "title": "Machine Learning",
    "section": "12 Neural Networks",
    "text": "12 Neural Networks\n  Code Exercise 1 \n  Code Exercise 2"
  },
  {
    "objectID": "teaching/machine_learning.html#project-based-learning",
    "href": "teaching/machine_learning.html#project-based-learning",
    "title": "Machine Learning",
    "section": "13 Project-Based Learning",
    "text": "13 Project-Based Learning\n  Panduan \nAkan di presentasikan pada pertemuan sebelum UAS, yaitu pada Rabu, 04 Juni 2025."
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "CC BY-NC-SA 4.0 license",
    "section": "",
    "text": "@2025 Deri Siswara. License adapted from Jadey Ryan\nOpinions expressed are solely my own and do not express the views of my employer or any organizations I am associated with.\nMy content is released under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA) license.\nYou may share and adapt this content with appropriate credit and notation of any changes. You may not use this material for any commercial purposes.\n\n\n\n Back to top"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Hi! I’m Deri Siswara 👋\n\n  View CV PDF  \n\n\n Professional Summary\nResearch/Data Analyst with a background in Statistics and Economics. Experienced in survey design, creating dashboards, impact assessment, econometric modeling, and teaching. Worked on various projects across multiple sectors, bringing unique and diverse perspectives to problem-solving.\n\n\n\n Education\n\nMSc in Statistics and Data Science, IPB University, 2024\nBachelor of Economics, IPB University, 2020\n\n\n\n\n Work Experience\n\nPerbanas Institute, Jakarta, ID\nAdjunct Lecturer (February 2025 - June 2025)\n\nTeaching Machine Learning course for the Data Science Program in the Faculty of Information Technology\nDeveloping curriculum and practical lab sessions for undergraduate students\n\n\n\nIPB University, Bogor, ID\nAssistant Lecturer (February 2021 - December 2024)\n\nTeaching courses including General Economics, Econometrics I, Econometrics II, Quantitative Methods, and Empirical Finance\n\n\n\n\n Major Projects\n\nNon-Cash Social Assistance Monitoring Survey 2025\nResearcher (May 2025 - October 2025) | Bank Indonesia\n\nDeveloped technical guidelines for implementing the Non-Cash Social Assistance Monitoring Survey 2025\nCreated data entry tools for survey result collection\nPrepared technical coordination materials for Bank Indonesia’s Domestic Representative Offices\nConducted data processing and analysis of the monitoring survey results\n\n\n\nImplementation Study of Food Safety in APEC Regions\nConsultant/Data Analyst (May 2025 - July 2025) | APEC Project: SCSC_102_2024T\n\nAnalyzed survey data on food safety management systems for street vendors and small businesses in APEC regions\nPresented findings at a stakeholder workshop in Bali, Indonesia (July 22-23, 2025)\n\n\n\nOutlier Detection Study in Banking Report Data\nConsultant/Data Analyst (June 2024 - March 2025) | Bank Indonesia\n\nResearched and implemented various statistical methods for outlier detection in daily and monthly banking report data\nIdentified optimal outlier detection methods and thresholds for improving the accuracy of financial reporting systems\nConducted knowledge sharing sessions\n\n\n\nSocio-Economic Impact Analysis of Subsidized Fuel Restrictions\nConsultant/Data Analyst (February 2024 - August 2024) | PT Pertamina (Persero)\n\nFocused on assessing the socio-economic impacts of subsidized fuel restrictions, including effects on poverty, unemployment, inflation, and economic growth\nApplied econometric methods, data analysis, microeconomics principles, and market research techniques\n\n\n\nFood Price Analysis\nConsultant/Data Analyst (May 2023 - November 2023) | KPPU\n\nAnalyzed the price transmission mechanism of 10 selected commodities using Nonlinear Autoregressive Distributed Lag (NARDL) models\n\n\n\nIn House Training (IHT)\nTrainer (October 2022) | Bank Indonesia Institute (BINS)\n\nConducted training on statistics and econometrics tools, covering courses such as univariate time series, multivariate time series, and panel data using RStudio\n\n\n\nCustomer Classification and Sector Mapping Study\nJunior Data Analyst (February 2022 - August 2022) | IPB University and PT. Pegadaian\n\nDeveloped customer classification model based on the probability of default using logistic regression\nConducted sectoral mapping of non-pawned products for each regional office of PT. Pegadaian\n\n\n\n\n\n Skills\n\nProgramming Languages: R, Python, SQL, HTML/CSS, Markdown, Typst\nStatistical Software: EViews, Stata, SPSS, RStudio, Jupyter Notebook\nData Visualization & Publishing: Tableau, Looker, Quarto\nResearch methods in economics and social sciences\nWork efficiency\n\n\n\n\n Publications\n  My Google Scholar  \nBooks: - Metode Kuantitatif dengan RStudio (2024) - IPB Press - Aplikasi Model Ekonometrika dengan RStudio (2024) - IPB Press\nJournal Articles: - Classification Modeling with RNN-based, Random Forest, and XGBoost for Imbalanced Data: A Case of Early Crash Detection in ASEAN-5 Stock Markets. (2024). Scientific Journal of Informatics, 11(3), 569-582 - Regional Tourism Development in Nusa Tenggara Barat: Maximizing Local Economic Development, EcceS: Economics Social and Development Studies 9 (2), 107-127 (2022)\nOther Publications: - Integrasi Pasar Saham Syariah Negara OKI dalam Krisis Pasar Saham Tiongkok dan Perang Dagang AS Tiongkok - Pemodelan Klasifikasi dengan RNN-based, Random Forest, dan XGBoost untuk Data Tidak Seimbang: Kasus Deteksi Dini Tekanan di Pasar Modal ASEAN-5 - Aplikasi Model Ekonometrika dengan RStudio Edisi Kedua - Aplikasi Model Ekonometrika dengan RStudio: Model Time-Series, Panel, Spatial\n\n\n\n Honor & Awards\n\nJabar Future Leaders Scholarship [Sep 2021]\nOral presentation - 12th International Conference on Islamic Economics & Finance [Aug 2020]\n\n\n\nBack to Top\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/book_econ.html",
    "href": "projects/book_econ.html",
    "title": "Application of Econometric Models with RStudio",
    "section": "",
    "text": "Site  Code\nThis is the code version of Application of Econometric Models with RStudio, a book released in 2024 by IPB Press. The book was written by Muhammad Firdaus, Tony Irawan, Fahmi Salam Ahmad, Hermanto Siregar, Deri Siswara, and Rodi Jakariya. You can order the full version here, which includes more detailed explanations.\nThis book aims to help students and researchers apply econometric models in analysis using RStudio software. It begins with an introduction to the use of R programming language and RStudio as an IDE. The book covers topics on theory and application of OLS models, including testing Gauss-Markov conditions. Additionally, it presents the application of time-series models such as ARMA, GARCH, VAR, VECM, ARDL, SVAR., static and dynamic panel data analysis using RStudio’s instruments that accommodate heteroscedasticity and autocorrelation assumptions. Finally, there is a discussion of spatial model applications for analysis with spatial or regional elements. In this latest publication update includes three additional chapters: spillover analysis on time series data; DCC-GARCH; Non-linear ARDL. Updates will be made frequently.\n\n\n\n\n Back to topCitationBibTeX citation:@online{siswara2024,\n  author = {Siswara, Deri},\n  title = {Application of {Econometric} {Models} with {RStudio}},\n  date = {2024-02-16},\n  url = {https://derisiswara.org/projects/book_econ.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nSiswara, Deri. 2024. “Application of Econometric Models with\nRStudio.” February 16, 2024. https://derisiswara.org/projects/book_econ.html."
  },
  {
    "objectID": "projects/book_multivariate.html",
    "href": "projects/book_multivariate.html",
    "title": "Quantitative Methods with RStudio: Application for Management and Business Research",
    "section": "",
    "text": "Site  Code\nThis is the code version of Application of Econometric Models with RStudio, a book released in 2024 by IPB Press. The book was written by Muhammad Firdaus, Tony Irawan, Fahmi Salam Ahmad, Hermanto Siregar, Deri Siswara, and Rodi Jakariya. You can order the full version here, which includes more detailed explanations.\nThis book aims to help students and researchers apply econometric models in analysis using RStudio software. It begins with an introduction to the use of R programming language and RStudio as an IDE. The book covers topics on theory and application of OLS models, including testing Gauss-Markov conditions. Additionally, it presents the application of time-series models such as ARMA, GARCH, VAR, VECM, ARDL, SVAR., static and dynamic panel data analysis using RStudio’s instruments that accommodate heteroscedasticity and autocorrelation assumptions. Finally, there is a discussion of spatial model applications for analysis with spatial or regional elements. In this latest publication update includes three additional chapters: spillover analysis on time series data; DCC-GARCH; Non-linear ARDL. Updates will be made frequently.\n\n\n\n\n Back to topCitationBibTeX citation:@online{siswara2024,\n  author = {Siswara, Deri},\n  title = {Quantitative {Methods} with {RStudio:} {Application} for\n    {Management} and {Business} {Research}},\n  date = {2024-02-16},\n  url = {https://derisiswara.org/projects/book_multivariate.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nSiswara, Deri. 2024. “Quantitative Methods with RStudio:\nApplication for Management and Business Research.” February 16,\n2024. https://derisiswara.org/projects/book_multivariate.html."
  }
]